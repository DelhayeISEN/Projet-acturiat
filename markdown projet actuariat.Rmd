---
title: "Projet Actuariat"
author: "Solène Corre, Florentin Dehooghe, François Delhaye"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    number_section: yes
    toc: yes
    toc_depth: 4
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
lang: fr
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE)
```

```{r}
# Installation des packages utilisées dans ce projet

#install.packages(c("xts","sp","zoo"))
#install.packages("Hmisc")
#install.packages(c("FactoMineR", "factoextra"))
#install.packages("cowplot")
#install.packages("summarytools")

# Installation du package CASdatasets contenant les 2 jeux de données sur lesquels nous allons travaillés

#install.packages("CASdatasets", repos = "http://dutangc.free.fr/pub/RRepos/", type="source")

# Importation des librairies nécessaires aux datasets

library(zoo)
library(xts)
library(sp)
library(CASdatasets)

# Chargement des 2 jeux de données freMPL1 et freMPL2
data(freMPL1)
data(freMPL2)
```

# Présentation du projet

L’assurance est un contrat par lequel, moyennant le versement d’une prime dont le montant est ﬁxé a priori (en début de période de couverture), l’assureur s’engage à indemniser l’assuré pendant toute la période de couverture (généralement un an). Cette prime doit reﬂéter le risque associé au contrat. 
Pour chaque police d’assurance, la prime est fonction de variables dites de tariﬁcation permettant de segmenter la population en fonction de son risque. Il est usuel d’utiliser une approche fréquence/sévérité ou une approche indemnitaire pour modéliser le coût annuel d’une police d’assurance. Sur les données utilisées dans ce projet, nous utiliserons cette dernière approche car on ne dispose pas des montants individuels de sinistre.
Le but de ce projet est de proposer un tariﬁcateur en se basant deux méthodes : les modèles linéaires généralisés (GLM) et les modèles additifs généralisés (GAM). Ces derniers sont une extension des GLM (proposé par McCullagh et Nelder, 1989) en considérant une approche non-paramétrique pour le prédicteur. 
Un second objectif sera, en plus de calculer une prime pure par police, de déterminer une commerciale intégrant une marge pour risque. Une approche par simulation sera réalisée pour juger de l’adéquation du chargement par rapport à la charge sinistre totale portefeuille.

# Exploration des jeux de données freMPL1 et freMPL2

Un peu à la manière du machine learning, les données contenues dans freMPL2 serviront de données d'entraînement de notre modèle et les données de freMPL1 serviront pour tester notre modèle final.

## Première visualisation des jeux de données 

```{r}
dim_freMPL1 <- dim(freMPL1)
dim_freMPL2 <- dim(freMPL2)
```

Les dimmensions du jeu de données **freMPL1** sont (`r dim_freMPL1`).
Ainsi, notre jeu contient `r dim_freMPL1[1]` données différentes, toutes définies par `r dim_freMPL1[2]` caractéristiques différentes. 

De même, les dimmensions du jeu de données **freMPL2** sont (`r dim_freMPL2`).
Ainsi, notre jeu contient `r dim_freMPL2[1]` données différentes, toutes définies par `r dim_freMPL2[2]` caractéristiques différentes. 

```{r, results='hide'}
colnames_freMPL1 <- colnames(freMPL1)
colnames_freMPL2 <- colnames(freMPL2) 
# Les noms des colonnes sont les mêmes. La seule différence entre nos 2 tableaux est l'inversion entre les colonnes RiskVar et ClaiAmount. 
# Regardons aussi les différents types d'objets figurant dans les colonnes :  
str(freMPL2)
# On constate qu'il y a de nombreux types de données : des données numériques, des données descriptives (ex : Il y a troix types de garages : "collective garage", "None" et "Private Garage")
```

Les noms des caractéristiques des jeux de données sont les mêmes. es différentes caractéristiques sont :

- **`r colnames_freMPL2[1]`** : il s'agit d'une donnée de type numérique qui correspond à la fréquence d'exposition aux risques d'un individu sur une année. Par exemple, si l'individu a été exposé 100 jours, le chiffre affiché est 0,27 (= 100/365,25).
- **`r colnames_freMPL2[2]`** : c'est un nombre entier de mois correspondant à l'âge de la licence de la personne concernée.
- **`r colnames_freMPL2[3]`** : cela correspond à la date de début d'exposition aux risques.
- **`r colnames_freMPL2[4]`** : c'est la date de fin d'exposition au risque. Si elle n'est pas renseigner, c'est que la personne est toujours exposée.
- **`r colnames_freMPL2[5]`** : Il correspond à l'âge du véhicule en année(s). Il est composé en 9 catégories distinctes : "0", "1", "2", "3", "4", "5", "6-7", "8-9" et "10+".
- **`r colnames_freMPL2[6]`** : c'est le sexe de l'individu.
- **`r colnames_freMPL2[7]`** : il s'agit du statut marital de la personne. Elle est soit célibataire ("Alone") soit autre chose ("Other").
- **`r colnames_freMPL2[8]`** : Cela correspond à la catégorie socioprofessionnelle de l'individu. Les valeurs, comprises entre "CSP1" et "CSP99", correspondent à la classification française (voir lien suivant : <https://fr.wikipedia.org/wiki/Professions_et_catégories_socioprofessionnelles_en_France>). 
- **`r colnames_freMPL2[9]`** : Cela correspond à l'utilisation du véhicule par le propriétaire. Il est soit privée ("Private"), soit professionnel ("Professional"), ...
- **`r colnames_freMPL2[10]`** : C'est l'âge du conducteur (en années). Pour rappel, en France, la conduite est possible à partir de 18 ans.
- **`r colnames_freMPL2[11]`** : il s'agit d'une valeur numérique spécifiant si oui ("1") ou non ("0") l'assurance comporte une limite kilométique.
- **`r colnames_freMPL2[12]`** : c'est un variable de type numérique, dont la valeur est comprise entre 50 et 350, précisant si la personne possède des bonus ou des malus. Si la valeur est inférieure à 100, l'individu a droit à des bonus. Sinon, la personne a des malus.
- **`r colnames_freMPL2[13]`** : il s'agit du type de modèle concerné par l'assurance de l'individu.
- **`r colnames_freMPL2[14]`** : c'est un indicateur correspondant au prix du véhicule. 
- **`r colnames_freMPL2[15]`** : cela correspond au type de moteur que possède le véhicule.
- **`r colnames_freMPL2[16]`** : cela correspond au type d'énergie consommé par le véhicule que possède le véhicule
- **`r colnames_freMPL2[17]`** : c'est la vitesse maximum que peut atteindre le véhicule. Les différentes catégories sont:"1-130 km/h", "130-140 km/h", "140-150 km/h", "150-160 km/h", "160-170 km/h", "170-180 km/h", "180-190 km/h", "190-200 km/h", "200-220 km/h", "220+ km/h".
- **`r colnames_freMPL2[18]`** : il s'agit de la classe du véhicule.
- **`r colnames_freMPL2[19]`** : Nombre compris entre 1 et 20 correspondant au risque inconnu probable.
- **`r colnames_freMPL2[20]`** : c'est le montant total de la garantie ) laquelle peut prétendre l'assuré.
- **`r colnames_freMPL2[21]`** : il s'agit du type de garage auquel se rend l'assuré.
- **`r colnames_freMPL2[22]`** : c'est un indicateur précisant si oui ou non l'assuré peut prétendre à une garantie.



Regardons maintenant les premiers éléments composant le jeu de données **freMPL1** :

```{r}
knitr::kable(t(head(freMPL1,3)))
```

et aussi les premiers éléments composants **freMPL2** : 

```{r}
knitr::kable(t(head(freMPL2,3)))
```

## Nettoyage de données

Remarquons qu'il serait intéressant de faire un peu de nettoyage de données avant d'effectuer quelconques travaux sur celles-ci.
Pour cela, nous allons créer une fonction qui servira à nettoyer les 2 data frames.

Cette fonction (appelée nettoyage_dataframe) prend l'un des deux data frames en paramètres et effectue les opérations suivantes :

- Suppression des données des individus assurés moins d'un jour (Exposure)
- Modification des données des individus ayant un ClaimAmount négatif
- Suppression de la colonne associée au sexe de la personne
- Réduction du nombre de catégories socioprofessionnels
- Traduction des données (VehBody, MariStat, VehUsage, VehEngine, VehEnergy, Garage)

```{r}
nettoyage_dataframe <- function(dt){
  
  # Suppression des données des individus assurés moins d'un jour (Exposure)
  dt <- subset(dt,dt$Exposure>1/365.25)
  
  # Modification des données des individus ayant un ClaimAmount négatif
  dt <- subset(dt,dt$ClaimAmount>=0)
  
  # Suppression de la colonne associée au sexe de la personne 
  dt <- dt[,-6]
  
  # Réduction du nombre de catégories socioprofessionnels
  levels(dt$SocioCateg) <- c(levels(dt$SocioCateg), "CSP4", "CSP6",
                                    "CSP9")
  for (i in 1:dim(dt)[1]){
    if (dt$SocioCateg[i]%in%c("CSP1","CSP16","CSP18","CSP19")){
      dt$SocioCateg[i]<-"CSP1"
      }
    if (dt$SocioCateg[i]%in%c("CSP2", "CSP20", "CSP21", "CSP22", "CSP23",
                                     "CSP25", "CSP26","CSP27", "CSP28")){
      dt$SocioCateg[i]<-"CSP2"
      }
    if (dt$SocioCateg[i]%in%c("CSP3", "CSP30", "CSP31", "CSP32", "CSP33",
                                     "CSP35", "CSP36","CSP37", "CSP38", "CSP39")){
      dt$SocioCateg[i]<-"CSP3"
      }
    if (dt$SocioCateg[i]%in%c("CSP40", "CSP41", "CSP42", "CSP43", "CSP46",
                                     "CSP47", "CSP48","CSP49")){
      dt$SocioCateg[i]<-"CSP4"
      }
    if (dt$SocioCateg[i]%in%c("CSP5", "CSP50", "CSP51", "CSP55", "CSP56", 
                                     "CSP57", "CSP59")){
      dt$SocioCateg[i]<-"CSP5"
      }
    if (dt$SocioCateg[i]%in%c("CSP6", "CSP60", "CSP61", "CSP62", "CSP63",
                                     "CSP65", "CSP66")){
      dt$SocioCateg[i]<-"CSP6"
      }
    if (dt$SocioCateg[i]%in%c("CSP7", "CSP70", "CSP73", "CSP74", "CSP77")){
      dt$SocioCateg[i]<-"CSP7"
      }
    if (dt$SocioCateg[i]%in%c("CSP9", "CSP91")){
      dt$SocioCateg[i]<-"CSP9"
      }
  }
  dt$SocioCateg <- droplevels(dt$SocioCateg)
  
  # Traduction des données (VehBody, MariStat, VehUsage, VehEngine, VehEnergy, Garage)
  for (i in 1:dim(dt)[2]){
    # Type de véhicules
    if (colnames(dt)[i]=="VehBody"){
      levels(dt$VehBody) <- c(levels(dt$VehBody), "autobus", "coupé",
                                     "autre microvan", "berline","SUV", "break",
                                     "camionnette")
      dt$VehBody[dt$VehBody == "bus"]<-"autobus"
      dt$VehBody[dt$VehBody == "coupe"]<-"coupé"
      dt$VehBody[dt$VehBody == "other microvan"]<-"autre microvan"
      dt$VehBody[dt$VehBody == "sedan"]<-"berline"
      dt$VehBody[dt$VehBody == "sport utility vehicle"]<-"SUV"
      dt$VehBody[dt$VehBody == "station wagon"]<-"break"
      dt$VehBody[dt$VehBody == "van"]<-"camionnette"
      dt$VehBody <- droplevels(dt$VehBody)
      }
    # Statut marital
    if (colnames(dt)[i]=="MariStat"){
      levels(dt$MariStat) <- c(levels(dt$MariStat), "célibataire", "autre")
      dt$MariStat[dt$MariStat == "Alone"]<-"célibataire"
      dt$MariStat[dt$MariStat == "Other"]<-"autre"
      dt$MariStat <- droplevels(dt$MariStat)
      }
    # Utilisation du véhicule
    if (colnames(dt)[i]=="VehUsage"){
      levels(dt$VehUsage) <- c(levels(dt$VehUsage), "privée", 
                                      "privée et trajet vers bureau", "professionnel", 
                                      "trajet professionnel" )
      dt$VehUsage[dt$VehUsage == "Private"]<-"privée"
      dt$VehUsage[dt$VehUsage == "Private+trip to office"]<-
      "privée et trajet vers bureau"
      dt$VehUsage[dt$VehUsage == "Professional"]<-"professionnel"
      dt$VehUsage[dt$VehUsage == "Professional run"]<-
      "trajet professionnel"
      dt$VehUsage <- droplevels(dt$VehUsage)
      }
    # Moteur du véhicule
    if (colnames(dt)[i]=="VehEngine"){
      levels(dt$VehEngine) <- c(levels(dt$VehEngine), 
                                       "injection directe surpuissante",
                                       "électrique", "injection surpuissante")
      dt$VehEngine[dt$VehEngine == "direct injection overpowered"]<-
      "injection directe surpuissante"
      dt$VehEngine[dt$VehEngine == "electric"]<-"électrique"
      dt$VehEngine[dt$VehEngine == "injection overpowered"]<-
      "injection surpuissante"
      dt$VehEngine <- droplevels(dt$VehEngine)
      }
    # Energie utilisée par le véhicule
    if (colnames(dt)[i]=="VehEnergy"){
      levels(dt$VehEnergy) <- c(levels(dt$VehEnergy), "électrique", "essence")
      dt$VehEnergy[dt$VehEnergy == "regular"]<-"essence"
      dt$VehEnergy[dt$VehEnergy == "eletric"]<-"électrique"
      dt$VehEnergy <- droplevels(dt$VehEnergy)
      }
    # Garage
    if (colnames(dt)[i]=="Garage"){
      levels(dt$Garage) <- c(levels(dt$Garage), "aucun", "garage indépendant",
                                    "concessionnaire")
      dt$Garage[dt$Garage == "None"]<-"aucun"
      dt$Garage[dt$Garage == "Private garage"]<-"garage indépendant"
      dt$Garage[dt$Garage == "Collective garage"]<-"concessionnaire"
      dt$Garage <- droplevels(dt$Garage)
    }
  }
  return (dt)
}
```

```{r}
# nettoyage de nos 2 data frames : 

freMPL2 <- nettoyage_dataframe(freMPL2)
freMPL1 <- nettoyage_dataframe(freMPL1)
```

## Statistiques descriptives 

Regardons maintenant plus précisement les valeurs particulières de ces colonnes (valeurs minimum et maximum, moyenne, médiane,quantiles, ...). Pour cela, on exécute l'instruction **summary(freMPLx)** (et plus précisement **dfSummary(freMPLx)** du package summarytools pour l'affichage) ce qui donne les résultats suivants : 

- Pour **freMPL1** :

```{r , results='asis'}
library(summarytools)
dfSummary(freMPL1, plain.ascii = FALSE,style = "grid", headings = FALSE, 
          graph.col = FALSE, valid.col = FALSE, lang = 'fr', dfSummary.silent = TRUE)
```

On constate ainsi que, pour ce data frame, l'âge moyen du conducteur est de 46,3 ans avec pour écart-type 14,9 ans. Le plus jeune conducteur a 18 ans(âge minimum légale pour conduire en France) et le plus âgé a 97 ans. L'écart interquartile (IQR), c'est-à-dire la mesure de dispersion qui s'obtient en faisant la différence entre le premier (25% des valeurs du data frame sont inférieures à ce quartile) et le troisième quartile(75 %), est de 23. Autrement dit, 50% des âges des conducteurs est compris entre 35 et 58 ans. Le coefficient de variation (CV), le rapport entre l'écart-type et la moyenne, est égale à 3. 
De même, en ce qui concerne l'usage du véhicule par son propriétaire, on remarquera que la plupart des personnes renseignées utilise leur véhicule pour les trajets privés et pour se rendre à leur bureau (44,1%).  


- Pour **freMPL2** :

```{r, results='asis'}
dfSummary(freMPL2, plain.ascii = FALSE, style = "grid", headings = FALSE, 
          graph.col = FALSE, valid.col = FALSE, lang = 'fr', dfSummary.silent = TRUE)
```

Pour ce data frame, l'âge moyen du conducteur est de 44,5 ans avec pour écart-type 14,7 ans. Le plus jeune conducteur a 18 ans(âge minimum légale pour conduire en France) et le plus âgé a 103 ans. L'écart interquartile (IQR) est de 23 ce qui veut dire que 50% des conducteurs ont un âge compris entre 33 et 56 ans. Le coefficient de variation (CV) est égale à 3. 
De même, en ce qui concerne l'usage du véhicule par son propriétaire, on remarquera que la plupart des personnes renseignées utilise leur véhicule pour les trajets privés et pour se rendre à leur bureau (46,4%).


On remarquera également qu'il existe des données manquantes, pour les 2 tableaux de données, dans la colonne RecEnd, ce qui signifie que les individus concernés sont toujours assurés.

On peut aussi utiliser la fonction **describe()** du package Hmisc pour avoir un aperçu de la dispersion des données. En effet, cette fonction détermine le type de la variable (character, factor, numeric,...) et affiche un "résumé" concis en fonction de chacun. Vous trouvez un exemple d'exécution de la focntion describe en annexe. 

```{r}
library("Hmisc")
describe_freMPL2 <- describe(freMPL2)
```


## Représentations graphiques des données

Dans cette partie, vous allez voir des représentations graphiques des colonnes les plus importantes de nos data frames. L'ensemble des graphiques est cependant disponible dans les annexes de ce rapport. 

```{r}
# On met les colonnes dans le même ordre

freMPL1 <- freMPL1[,c(1:17,19,18,20:21)]
library("ggplot2")
library("dplyr") 
library("cowplot")

representation_graphique <- function(dataframe, col){
  indice_col <-  which(colnames(dataframe) == col)
  if(indice_col %in% c(1,2,9,11,18,19)){
    par(fig=c(0.1,1,0.1,0.7), mar = c(0,0,2,2))
    hist(dataframe[,indice_col],
      main = paste(col))
    par(fig=c(0.1,1,0.8,1), mar = c(0,0,2,2), new = TRUE)
    boxplot(dataframe[,indice_col], data = dataframe, horizontal = TRUE)
  }else{
    if(indice_col %in% c(5)){
      dt <- data.frame(
        class = c("0","1","2","3","4","5","6-7","8-9","10+"),
        n = as.data.frame(table(dataframe[,indice_col]))[,2],
        prop = as.data.frame(round(prop.table(table(dataframe[,indice_col])),2))[,2]
        )
      dt <- dt %>%
        arrange(desc(class)) %>%
        mutate(lab.ypos = cumsum(prop) - 0.5*prop)
      barre <- ggplot(dt, aes(x = class, y = n, fill = class)) +
        geom_bar(width = 1, stat = "identity", color = "white")+
        theme_minimal()
      camembert <- ggplot(dt, aes(x = "", y = prop, fill = class)) +
        geom_bar(width = 1, stat = "identity", color = "white") +
        coord_polar("y", start = 0)+
        geom_text(aes(y = lab.ypos, label = prop), color = "white")+
        theme_void()
      plot_grid(barre, camembert, ncol = 2, nrow = 1)
    }else{
      if(indice_col %in% c(10,21)){
        dt <- data.frame(
          class = c("0","1"),
          n = as.data.frame(table(dataframe[,indice_col]))[,2],
          prop = as.data.frame(round(prop.table(table(dataframe[,indice_col])),2))[,2]
          )
        dt <- dt %>%
          arrange(desc(class)) %>%
          mutate(lab.ypos = cumsum(prop) - 0.5*prop)
        barre <- ggplot(dt, aes(x = class, y = n, fill = class)) +
          geom_bar(width = 1, stat = "identity", color = "white")+
          theme_minimal()
        camembert <- ggplot(dt, aes(x = "", y = prop, fill = class)) +
          geom_bar(width = 1, stat = "identity", color = "white") +
          coord_polar("y", start = 0)+
          geom_text(aes(y = lab.ypos, label = prop), color = "white")+
          theme_void()
        plot_grid(barre, camembert, ncol = 2, nrow = 1)
      }else{
        dt <- data.frame(
          class = levels(dataframe[,indice_col]),
          n = as.data.frame(table(dataframe[,indice_col]))[,2],
          prop = as.data.frame(round(prop.table(table(dataframe[,indice_col])),2))[,2]
          )
        dt <- dt %>%
          arrange(desc(class)) %>%
          mutate(lab.ypos = cumsum(prop) - 0.5*prop)
        barre <- ggplot(dt, aes(x = class, y = n, fill = class)) +
          geom_bar(width = 1, stat = "identity", color = "white")+
          theme_minimal()
        camembert <- ggplot(dt, aes(x = "", y = prop, fill = class)) +
          geom_bar(width = 1, stat = "identity", color = "white") +
          coord_polar("y", start = 0)+
          geom_text(aes(y = lab.ypos, label = prop), color = "white")+
          theme_void()
        plot_grid(barre, camembert, ncol = 2, nrow = 1)
      }
    }
  }
}
```

```{r, eval = FALSE}
png(file = "graphique/Exposure1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[1])
dev.off()
png(file = "graphique/LicAge1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[2])
dev.off()
png(file = "graphique/VehAge1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[5])
dev.off()
png(file = "graphique/MariStat1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[6])
dev.off()
png(file = "graphique/SocioCateg1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[7])
dev.off()
png(file = "graphique/VehUsage1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[8])
dev.off()
png(file = "graphique/DrivAge1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[9])
dev.off()
png(file = "graphique/HasKmLimit1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[10])
dev.off()
png(file = "graphique/BonusMalus1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[11])
dev.off()
png(file = "graphique/VehBody1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[12])
dev.off()
png(file = "graphique/VehPrice1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[13])
dev.off()
png(file = "graphique/VehEngine1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[14])
dev.off()
png(file = "graphique/VehEnergy1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[15])
dev.off()
png(file = "graphique/VehMaxSpeed1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[16])
dev.off()
png(file = "graphique/VehClass1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[17])
dev.off()
png(file = "graphique/RiskVar1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[18])
dev.off()
png(file = "graphique/ClaimAmount1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[19])
dev.off()
png(file = "graphique/Garage1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[20])
dev.off()
png(file = "graphique/ClaimInd1.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL1)[21])
dev.off()

png(file = "graphique/Exposure2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[1])
dev.off()
png(file = "graphique/LicAge2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[2])
dev.off()
png(file = "graphique/VehAge2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[5])
dev.off()
png(file = "graphique/MariStat2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[6])
dev.off()
png(file = "graphique/SocioCateg2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[7])
dev.off()
png(file = "graphique/VehUsage2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[8])
dev.off()
png(file = "graphique/DrivAge2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[9])
dev.off()
png(file = "graphique/HasKmLimit2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[10])
dev.off()
png(file = "graphique/BonusMalus2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[11])
dev.off()
png(file = "graphique/VehBody2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[12])
dev.off()
png(file = "graphique/VehPrice2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[13])
dev.off()
png(file = "graphique/VehEngine2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[14])
dev.off()
png(file = "graphique/VehEnergy2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[15])
dev.off()
png(file = "graphique/VehMaxSpeed2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[16])
dev.off()
png(file = "graphique/VehClass2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[17])
dev.off()
png(file = "graphique/RiskVar2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[18])
dev.off()
png(file = "graphique/ClaimAmount2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[19])
dev.off()
png(file = "graphique/Garage2.png", width = 800, height = 700)
representation_graphique(freMPL2,colnames(freMPL2)[20])
dev.off()
png(file = "graphique/ClaimInd2.png", width = 800, height = 700)
representation_graphique(freMPL1,colnames(freMPL2)[21])
dev.off()
```






## Méthodes des composantes principales

Nous allons maintenant rentrer dans des méthodes d'analyse descriptives plus complètes pour nous permettre d'établir nos modèles linéaires. Pour cela, nous allons appliquer les méthodes d'analyse en composantes principales (ACP) et d'analyse factorielle des correspondances (AFC). Le but de ces méthodes est de définir les informations les plus significatives de nos data frames et de découvrir si oui ou non il existe certaines similitudes entre nos différentes informations pour pouvoir obtenir un data frame optimisé sur lequel on appliquera nos 2 modèles linéaires (GLM, GAM).

### Analyse en composantes principales (ACP) 

L'ACP permet d’analyser et de visualiser un jeu de données contenant des individus décrits par plusieurs variables quantitatives.
C’est une méthode statistique qui permet d’explorer des données dites multivariées (données avec plusieurs variables). Chaque variable pourrait être considérée comme une dimension différente.
L’analyse en composantes principales est utilisée pour extraire et de visualiser les informations importantes contenues dans une table de données multivariées. L’ACP synthétise cette information en seulement quelques nouvelles variables appelées composantes principales. Ces nouvelles variables correspondent à une combinaison linéaire des variables originels. Le nombre de composantes principales est inférieur ou égal au nombre de variables d’origine.

#### Calcul de l'ACP

Pour réaliser le calcul de l'ACP, plusieurs fonctions, de différents packages, sont disponibles dans le logiciel R :

- *prcomp()* et *princomp()* issus du package *stats*
- *PCA()* issu du package *FactoMineR*
- *dudi.pca()* issu du package *ade4*
- *epPCA()*  issu du package *ExPosition*.

Parmi ces fonctions, nous avons decider d'utiliser la fonction **PCA()** du package **FactoMineR** car ce package nous permettra également de réaliser notre seconde analyse. Enfin, pour extraire et visualiser les résultats, nous allons utiliser les fonctions R fournies par le package **factoextra**.

Nous allons donc exécuter l'ACP sur notre tableau freMPL2 en prenant à ce que l'ensemble des valeurs que nous utilisons soit de type numérique (quitte à réaliser une conversion sur certaines de nos colonnes).  

```{r}
freMPL2$LicAge <- as.numeric(freMPL2$LicAge)
freMPL2$DrivAge <- as.numeric(freMPL2$DrivAge)
freMPL2$HasKmLimit <- as.numeric(freMPL2$HasKmLimit)
freMPL2$BonusMalus <- as.numeric(freMPL2$BonusMalus)
freMPL2$RiskVar <- as.numeric(freMPL2$RiskVar)
freMPL2$ClaimAmount <- as.numeric(freMPL2$ClaimAmount)
freMPL2$ClaimInd <- as.numeric(freMPL2$ClaimInd)
```

Une fois que nos données ont été converties, il faut veiller à la *standardisation des données*. Pour cela, on normalise nos variables afin que le résultat de l'ACP obtenue ne soient pas affecté (par exemple, par des différences d'unités). 
Ainsi, l'objectif est de rendre les variables comparables en les normalisant généralement de manière à ce qu'elles aient un écart type égal à 1 et une moyenne nulle.
L'approche consiste à transformer les données en soustrayant à chaque valeur une valeur de référence (la moyenne de la variable) et en la divisant par l’écart type.
Pour normaliser les données, il est possible d'utiliser la fonction *scale()*. Cependant, par défaut, le fonction PCA() normalise automatiquement les données. Nous n'avons pas eu besoin de faire cette transformation. 

```{r}
library("FactoMineR")
library("factoextra") # Pour la visualisation 
freMPL2.active <- freMPL2[,c(1:2,9:11, 18:19,21)]
```

Réalisons maintenant notre Analyse en Composantes Principales. Pour cela, il faut exécuter la commande suivante : 

```{r, echo = TRUE}
freMPL2.pca <- PCA(freMPL2.active, ncp = 5, graph = FALSE)
```

Notre fonction PCA() prend en compte un data frame freMPL2.active qui correspond aux colonnes du dataframe freMPL2 qui sont de type numérique et que l'on souhaite analyser, un paramètre ncp qui correspond au nombre de dimensions conservées dans les résultats finaux (par défaut, ce nombre est égal à 3) et un paramètre logique graph qui précise si oui (graph = TRUE) ou non (graph = FALSE) nous voulons qu'un graphique du résultat s'affiche.

La fonction PCA() crée un objet contenant de nombreuses informations comme les valeurs propres (la variance du facteur correspondant où un facteur est une combinaison linéaire des variables initiales), la moyenne et l'écart type des variables, le poids de ces variables, ... 


#### Analyse des résultats

##### Valeurs propres

Regardons d'abord les **valeurs propres**. Elles mesurent la quantité de variance expliquée par chaque axe prinicipal.

Examinons donc ces valeurs propres (eigenvalue en anglais) afin de déterminer le nombre de composantes principales à prendre en considération. Les valeurs propres et la proportion de variances retenues par les composantes principales peuvent être extraites à l'aide de la fonction *get_eignevalue()* du package *factoextra*.

Voici le résultat que l'on obtient :

```{r}
knitr::kable(get_eigenvalue(freMPL2.pca))
```

Dans ce tableau, nous avons les valeurs propres de chacune des 8 colonnes du dataframe freMPL2.active (Exposure, LicAge, DrivAge, HasKmLimit, BonusMalus, RiskVar, ClaimAmount, ClaimInd), la proportion de variance associée et la variance cumulée.

La somme de toutes les valeurs propres donne une variance total de 8 (le nombre de dimensions). Pour obtenir la proportion de variance de la deuxième colonne, il suffit de prendre la valeur propre associée, de diviser cette valeur par le nombre de dimensions et de le mettre en pourcentage. Par exemple, pour la dimension 1, 2,3406825 divisé par 8 donne 0,29258531, ce qui donne 29,2585314% de la variance. Enfin, la dernière colonne correspond à la somme cumulée des variances. Par exemple, 59.02856 correspond à la somme de 12.7801347 avec 16.9898931 et 29.2585314. 

On notera ainsi qu'environ 46,25% de la variance totale est expliquée par nos 2 premières dimensions.

On peut utiliser ses valeurs propres pour déterminer le nombre d'axes principaux à conserver après l'ACP :

- Une valeur propre > 1 indique que la composante principale  concernée représente plus de variance par rapport à une seule variable d’origine, lorsque les données sont standardisées. Ceci est généralement utilisé comme seuil à partir duquel les PC sont conservés (Dans ce cas, on aurait 3 composantes principales).
- On peut également limiter le nombre d’axes à un nombre qui représente une certaine fraction de la variance totale. Par exemple, si vous êtes satisfaits avec 70% de la variance totale expliquée, utilisez le nombre d’axes pour y parvenir (Dans ce cas, on aurait 4 dimensions).

Une autre méthode pour déterminer le nombre de composantes principales est de regarder le graphique des valeurs propres (appelé **scree plot**). Le nombre d’axes est déterminé par le point, au-delà duquel les valeurs propres restantes sont toutes relativement petites et de tailles comparables. 

Le graphique des valeurs propres peut être généré à l’aide de la fonction *fviz_eig()* ou *fviz_screeplot()* du package *factoextra*.

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
fviz_eig(freMPL2.pca, addlabels = TRUE, ylim = c(0,33))
```

Du graphique ci-dessus, nous pourrions vouloir nous arrêter à la cinquième composante principale puisque environ 83% des informations contenues dans les données sont conservées par les cinq premières composantes principales.

##### Les variables

Pour extraire les résultats pour les variables, à partir de l'ACP, il est possible d'utiliser la fonction *get_pca_var()*. Cette fonction retourne une liste d'éléments contenant tous les résultats pour les variables actives (coordonnées, corrélation entre les variables et les axes, cosinus-carré et contributions).

Les composants de get_pca_var() peuvent être utilisés dans le graphique des variables comme suit :

- *get_pca_var()$coord* : coordonnées des variables pour créer un nuage de points.
- *get_pca_var()$cos2* (cosinus carré des variables) : Représente la qualité de représentation des variables sur le graphique de l'ACP. Il est calculé comme étant les coordonnées au carré.
- *get_pca_var()$contrib* : contient les contributions des variables aux composantes principales. 

###### Cercle de corrélation

Dans ce qui va suivre, nous allons visualiser les variables et tirer des conclusions à propos de leurs corrélations.

La corrélation entre une variable et une composante principale est utilisée comme coordonnées de la variable sur la composante principale. La représentation des variables diffère de celle des observations : les observations sont représentées par leurs projections, mais les variables sont représentées par leurs corrélations. 

Visualisons d'abord les variables :

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
fviz_pca_var(freMPL2.pca, repel = TRUE)
```

Le graphique ci-dessus est également connu sous le nom de **graphique de corrélation des variables**. Il montre les relations entre toutes les variables. Il peut être interprété comme suit:

- Les variables positivement corrélées sont regroupées.
- Les variables négativement corrélées sont positionnées sur les côtés opposés de l’origine du graphique (quadrants opposés).
- La distance entre les variables et l’origine mesure la qualité de représentation des variables. Les variables qui sont loin de l’origine sont bien représentées par l’ACP.

###### Qualité de la représentation

Pour visualiser la qualité de la représentation des variables sur la carte de l'ACP, nous allons utiliser le cosinus carré (*cos2*). Visualisons d'abord le cosinus carré des variables sur toutes les dimensions en utilisant le package *corrplot*. Voici le résultat : 

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
library("corrplot")
corrplot(get_pca_var(freMPL2.pca)$cos2, is.corr=FALSE)
```

On remarquera qu'avec 5 axes principaux l'ensemble des 8 variables utilisées dans notre ACP sont plutôt bien représentées.

Pour visualiser le cosinus carré, nous aurions pu utiliser aussi la fonction *fviz_cos2()* du package *factoextra* pour créer un diagramme bâton du cosinus carré des variables. 

Plus la valeur du cosinus carré est élévée, plus la réprésentation de la variable sur les axes prinicipaux pris en considération est bonne. Dans ce cas-là, la variable est positionnée à proximité de la circonférence du cercle de corrélation et le point associé dans le tableau de corrélation est gros et de couleur foncé.
Inversement, un faible cosinus carré indique que la variable n’est pas parfaitement représentée par les axes principaux. Dans ce cas, la variable est proche du centre du cercle et le point du tableau de corrélation est petit (voir inexistant). 

Il est également possible de colorer les variables en fonction de la valeur de leurs cosinus carré.  

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
fviz_pca_var(freMPL2.pca, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Évite le chevauchement de texte
             )
```

On remarquera donc que les variables DrivAge et LicAge sont bien représentées par nos axes principaux tandis que la variable RiskVar n'est pas bien représenté par nos axes. 

###### Contribution des variables aux axes principaux

Observons maintenant la contribution des variables aux axes principaux. 

Les contributions des variables dans la définition d'un axe principal donné sont exprimées en pourcentage :

- Les variables corrélées par nos deux premiers axes sont les plus importantes pour expliquer la variabilité dans le jeu de données. 
- Les variables qui ne sont pas en corrélation avec un axe ou qui sont corrélées avec les derniers axes sont des variables à faible apport et peuvent être supprimées pour simplifier l’analyse globale.

Comme pour la visualisation du cosinus carré, il est possible d’utiliser la fonction *corrplot()* pour mettre en évidence les variables les plus contributives pour chaque dimension:

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
corrplot(get_pca_var(freMPL2.pca)$contrib, is.corr=FALSE) 
```

Grâce à ce graphique, on constate, par exemple, que les variables LicAge, DrivAge et BonusMalus représentent la première dimension (le premier axe principal). 

La fonction *fviz_contrib()* peut être utilisée pour créer un diagramme bâton de la contribution des variables pour voir plus précisement la répartition des varaibles selon l'axe principal. 

```{r, fig.align='center'}
f1 <- fviz_contrib(freMPL2.pca, choice = "var", axes = 1, top = 4, title = "Dim-1", ylim = c(0,65))
f2 <- fviz_contrib(freMPL2.pca, choice = "var", axes = 2, top = 4, title = "Dim-2", ylim = c(0,65))
f3 <- fviz_contrib(freMPL2.pca, choice = "var", axes = 3, top = 4, title = "Dim-3", ylim = c(0,65))
f4 <- fviz_contrib(freMPL2.pca, choice = "var", axes = 4, top = 4, title = "Dim-4", ylim = c(0,65))
f5 <- fviz_contrib(freMPL2.pca, choice = "var", axes = 5, top = 4, title = "Dim-5", ylim = c(0,65))

plot_grid(f1,f2,f3,f4,f5, ncol = 5, nrow = 1, align = "h")
```

La ligne en pointillé rouge, sur les graphiques ci-dessus, indique la contribution moyenne attendue (dans notre cas, il est de 12,5%). Pour une composante donnée, une variable avec une contribution supérieure à ce seuil pourrait être considérée comme importante pour contribuer à la composante.

Enfin, on peut mettre en évidence les variables les plus importantes sur le graphe de corrélation. 

```{r, fig.width = 4, fig.height = 4, fig.align='center'}
fviz_pca_var(freMPL2.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE
             )
```

Au final, on notera que 5 de nos variables ont plus d'importances que les autres : l'age du conducteur, l'âge de la licence de ce conducteur, son bonus ou son malus, s'il a eu un accident pendant qu'il était assuré et le montant auquel il peut prendre prétendre. 
On a également vu que nos 8 variables peuvent être réduites en 5 nouvelles variables qui sont des combinaisons linéaires des anciennes variables, sans pour autant perdre d'informations ou très peu (17% de l'ensemble de nos données). 

### Analyse factorielle des correspondances (AFC)

L’ analyse factorielle des correspondances est une extension de l’analyse en composantes principales pour analyser l’association entre deux variables qualitatives (ou catégorielles).
L’AFC permet de résumer et de visualiser l’information contenue dans le tableau de contingence formé par les deux variables catégorielles. Le tableau de contingence contient les fréquences formées par les deux variables.
Il retourne les coordonnées des éléments des colonnes et des lignes du tableau de contingence. Ces coordonnées permettent de visualiser graphiquement l’association entre les éléments de lignes et de colonnes dans un graphique à deux dimensions.

Nous verrons donc comment calculer et interpréter l’AFC et nous tenterons de définir les éléments les plus importants expliquant les variations dans le jeu de données. 

#### Calcul

Plusieurs fonctions de différents packages sont disponibles dans le logiciel R pour calculer l’AFC:

- *CA()* du package *FactoMineR*
- *ca()* du package *ca*
- *dudi.coa()* du package *ade4*
- *corresp()* du package *MASS*
- *epCA()* du package *ExPositio*

Cependant, nous allons utiliser la fonction *CA()* du package *FactoMineR* pour l'analyse et le package *factoextra* afin d'extraire et de visualiser les résultats de l’AFC.

```{r}
library ("FactoMineR")
```

Réalisons maintenant notre Analyse factorielle des correspondances. Pour cela, il faut exécuter la commande suivante : 
```{r, echo=TRUE}
freMPL2.ca <- CA (freMPL2.active, ncp=5, graph = FALSE)
```

Comme pour la fonction PCA() pour l'Analyse des Composantes Principales, notre fonction CA() prend en compte le data frame freMPL2.active que l'on souhaite analyser, le paramètre ncp qui correspond au nombre de dimensions conservées dans les résultats finaux et un paramètre logique graph qui précise si oui (graph = TRUE) ou non (graph = FALSE) nous voulons qu'un graphique du résultat s'affiche.

La fonction CA() crée un objet contenant de nombreuses informations sous forme de listes ou de matrices comme les valeurs propres (la variance du facteur correspondant où un facteur est une combinaison linéaire des variables initiales), le poids des lignes et des colonnes, le cosinus carré des lignes et des colonnes ... 

#### Analyse des résultats

Pour analyser les résultats de notre AFC, nous pouvons utiliser les fonctions fournies par le package *factoextra* comme :

- *get_eigenvalue(freMPL2.ca)* pour obtenir les valeurs propres expliquées par chaque axe principal
- *fviz_eig(freMPL2.ca)* pour visualiser ces valeurs propres
- *get_ca_row(freMPL2.ca)* et *get_ca_col(freMPL2.ca)* pour avoir les résultats associés aux lignes ou aux colonnes.
- *fviz_ca_row(freMPL2.ca)* et  *fviz_ca_col(freMPL2.ca)* pour visualiser ces résultats.

##### Conformité statistique : test de chi2

Pour interpréter l'AFC, la première étape consiste à évaluer s'il existe une dépendance significative entre les lignes et les colonnes. 
Une méthode consiste à utiliser le test statistique *chi2* pour examiner l'association entre les modalités des lignes et celles des colonnes. Dans notre exemple, l'association est très significative puisque nous avons un résultat pour chi-square égal à 22101115 pour une p-value nulle (Un score élevé signifie un lien fort entre les lignes et les colonnes).

##### Valeurs propres

L’observation des valeurs propres permet de déterminer le nombre d’axes principaux à considérer. Elles correspondent à la quantité d’informations retenue par chaque axe. Elles sont grandes pour le premier axe et petites pour l’axe suivant.
Les valeurs propres et la proportion de variances pour les différents axes peuvent être extraites à l’aide de la fonction *get_eigenvalue()*. 

```{r}
knitr::kable(get_eigenvalue(freMPL2.ca))
```

Les dimensions sont ordonnées de manière décroissante et listées en fonction de la quantité de variance expliquée. La dimension 1 explique la plus grande variance, suivie de la dimension 2 et ainsi de suite.

Le pourcentage cumulé expliqué est obtenu en ajoutant les proportions successives de variances expliquées pour obtenir le total courant. Par exemple, 87.89% plus 10.96% est égal à 98.85%. Par conséquent, environ 98.85% de la variance totale est expliquée par les deux premières dimensions.

Les valeurs propres peuvent être utilisées pour déterminer le nombre d’axes à retenir. Il n’y a pas de «règle générale» pour choisir le nombre de dimensions à conserver pour l’interprétation des données.

Dans notre analyse, les deux premiers axes expliquent 98.85% de la variance totale. C’est un pourcentage plus qu'acceptable.

Il est également possible de calculer une valeur propre moyenne au-dessus de laquelle l’axe doit être conservé dans le résultat. Dans notre cas, prenons 12,5% (1*100/8) comme valeur propre moyenne.Ainsi, tout axe avec une contribution supérieure devrait être considéré comme important et inclus dans la solution pour l’interprétation des données.

On peut voir cela sur le graphique des valeurs propres afin de déterminer le nombre de dimensions à l’aide de la fonction ou *fviz_screeplot()*.

```{r,fig.width = 4, fig.height = 4, fig.align='center'}
fviz_screeplot (freMPL2.ca, addlabels = TRUE)+
  geom_hline (yintercept = 12.5, linetype = 2, color = "red")
```

Selon le graphique ci-dessus, seule la dimension 1 doit être considérées pour l’interprétation de la solution. La dimension 2 explique seulement 11% de l’inertie totale, ce qui est inférieur à la valeur moyenne des axes (12,5%) et trop petit pour être éventuellement conservé pour une analyse plus approfondie.

La dimension 1 explique environ 87,9% de l’inertie totale. Plus la rétention est élevée, plus la subtilité contenue dans les données d’origine est conservée dans la solution de l’AFC à faible dimension.

#### Les variables colonnes

La fonction *get_ca_col()* sert à extraire les résultats pour les colonnes. Cette fonction renvoie une liste contenant les coordonnées, le cos2, la contribution et l’inertie des colonnes.

##### Qualité et contribution pour les colonnes

Pour visualiser la qualité et la contribution des colonnes dans notre tableau de données, on peut utiliser la fonction *fviz_ca_col()*. Voici ce qu'elle affiche : 

```{r}
fviz_ca_col (freMPL2.ca, col.col = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)
```

Comme pour l'ACP, on constate que 5 variables sont plutôt bien représentés. En effet, les colonnes LicAge, DrivAge, ClaimAmount, BonusMalus et RiskVar sont les variables les mieux représentées. 

# GLM 

Les modèles linéaires généralisés aussi appelés GLM sont une extension des modèles linéaires classiques. 

Cependant les modèles linéaires classiques sont utilisés uniquement lorsque la variable réponse est de type numérique continue. Or dans le cas que nous étudions, nous allons principalement utiliser des variables binaires avec lesquelles nous devrons utiliser la loi de Bernouilli.
De ce fait l’erreur qui résulte de notre modèle linéaire classique ne peut donc pas suivre une loi normale de moyenne nulle et de variance constante, nos résultats étant soit 0 ou 1.

Un GLM est composé de trois éléments :
1.	Un prédicteur linéaire
2.	Une fonction de lien
3.	Une structure des erreurs

Les prédicteurs linéaires sont un ensemble de variables prédictives induisant une variable dépendante que l’on nomme réponse.
$$\eta \; = \sum_{j=1}^{p} \beta_j\;X_{ij}$$

La fonction de lien est une transformation par une fonction mathématique de la prédiction moyenne. Il s’agit donc d’une fonction qui transforme les valeurs du prédicteur linéaire. G étant ici notre fonction lien
$$g(µ_y) =\sum_{j=1}^{p} \beta_j\;X_{ij}$$

Le but d’une fonction de lien est primordial dans notre exemple, celle-ci va contraindre les valeurs prédites dans l’échelle des valeurs observées. On comprendra alors que cette fonction lien nous est nécessaire pour pouvoir analyser nos variables binaires.

Enfin la structure des erreurs va donc devoir être adaptée par rapport à nos modèles linéaires classique afin qu’ils puissent correspondre à nos nouvelles données. Pour cela il existe plusieurs lois comme la loi de Poisson ou la loi Binomiale nous offrant une distribution des erreurs et des réponses qui seront différents.

La loi de Poisson est principalement utilisée lorsqu’il s’agit de problèmes de comptage (nombre de poissons dans une rivière, nombre de buts marqués dans une saison etc.)

Lorsque les données sont continues, nous pouvons donc utiliser une distribution Gaussienne, mais il existe également des distributions Binomiales négatives qui a pour but de modéliser des variables de comptage lorsque celles-ci sont sur-dispersées

Ainsi, dans notre cas les distribution de Poisson ou binomiale négative peuvent être utiliser pour représenter les fréquences des sinistres

Et Gamma et Inverse gauss pour représenter la sévérité des sinistres

## Fréquence des sinistres

### Présentation des lois utilisables

### Exécution du GLM sur notre tableau freMPL2
```{r}
# Modification faite sur les données DrivAge et BonusMalus

freMPL2$DrivAge <- cut(freMPL2$DrivAge, breaks = c(17, 4:16*5,104))
freMPL2$BonusMalus <- cut(freMPL2$BonusMalus, breaks = c(49,100,350))

```

Test du modèle GLM avec la loi de Poisson : 

```{r, echo = TRUE}

#calibration d’une loi de Poisson
glm1 <- glm(ClaimInd~DrivAge+VehAge+VehUsage+BonusMalus+VehBody+VehMaxSpeed, offset = log(Exposure), family=poisson("log"), data=freMPL2)
summary(glm1)

#glm1$aic
#glm1$null.deviance
#glm1$deviance
#glm1$iter
predict1 <- predict(glm1, freMPL2, type = 'response')
recap1 <- data.frame(ClaimInd = freMPL2$ClaimInd,
                     Predict_ClaimInd = predict1,
                     difference = abs(freMPL2$ClaimInd- predict1))
head(recap1,10)
recap1[recap1$difference<0.5 & recap1$ClaimInd == 1,]
 # Ce modèle ne fonctionne pas pour prédire les ClaimInd égaux à 1
```

Le résumé de notre modèle révèle des informations intéressantes. La performance d'une régression logistique est évaluée avec des métriques clés spécifiques :
- AIC (Critère d'information d'Akaike): Il mesure l'ajustement lorsqu'une pénalité est appliquée au nombre de paramètres. Des valeurs AIC plus petites indiquent que le modèle est plus proche de la vérité. 
- Null deviance : Il s'agit de la déviance du modèle nul, c'est-à-dire qu'il 'est caractérisé par aucun facteur.
- Residual deviance : Il s'agit de la déviance du modèle avec toutes les variables. 
- Number of Fisher Scoring iterations : Il s'agit du nombre d'itérations avant la convergence.

## Sévérité des sinistres

### Présentation des lois utilisables

#### loi de gamma (ou d'Euler)

```{r}
x_dgamma<- seq(0, 20, by = 0.01) 
y_dgamma1 <- dgamma(x_dgamma, shape = 1, scale = 2)
y_dgamma2 <- dgamma(x_dgamma, shape = 2, scale = 2)
y_dgamma3 <- dgamma(x_dgamma, shape = 3, scale = 2)
y_dgamma4 <- dgamma(x_dgamma, shape = 5, scale = 1)
y_dgamma5 <- dgamma(x_dgamma, shape = 9, scale = 0.5)
y_dgamma6 <- dgamma(x_dgamma, shape = 7.5, scale = 1)
y_dgamma7 <- dgamma(x_dgamma, shape = 0.5, scale = 1)
# shape correspond à alpha et scale correspond à beta 

plot(x_dgamma, y_dgamma1, type = "l",col = "red",main = "distribution de loi gamma", xlab = " ", ylab = " ")
lines(x_dgamma, y_dgamma2, col = "orange")
lines(x_dgamma, y_dgamma3, col = "yellow")
lines(x_dgamma, y_dgamma4, col = "green")
lines(x_dgamma, y_dgamma5, col = "black")
lines(x_dgamma, y_dgamma6, col = "blue")
lines(x_dgamma, y_dgamma7, col = "purple")
legend("topright", legend = c("alpha = 1 et beta = 2", "alpha = 2 et beta = 2", "alpha = 3 et beta = 2","alpha = 5 et beta = 1", "alpha = 9 et beta = 0.5", "alpha = 7.5 et beta = 1", "alpha = 0.5 et beta = 1"),lty = 1, col = c("red", "orange", "yellow", "green", "black", "blue", "purple"))
```

#### Inverse gauss

```{r}
#install.packages("statmod")
library("statmod")
x_dinvgauss <- seq(0, 5, by = 0.01) 
y_dinvgauss1 <- dinvgauss(x_dinvgauss, 1, 1) 
y_dinvgauss2 <- dinvgauss(x_dinvgauss, 1, 0.2) 
y_dinvgauss3 <- dinvgauss(x_dinvgauss, 1, 3) 
y_dinvgauss4 <- dinvgauss(x_dinvgauss, 3, 1) 
plot(x_dinvgauss, y_dinvgauss1, type = "l",col = "green",main = "distribution de loi inverse gaussienne", xlab = " ", ylab = " ")
lines(x_dinvgauss, y_dinvgauss2, col = "red")
lines(x_dinvgauss, y_dinvgauss3, col = "blue")
lines(x_dinvgauss, y_dinvgauss4, col = "orange")
legend("topright", legend = c("mu = 1 et lambda = 1", "mu = 1 et lambda = 0.2", "mu = 1 et lambda = 3","mu = 3 et lambda = 1"),lty = 1, col = c("green", "red", "blue", "orange"))
```

```{r}
glm4 <- glm(ClaimAmount~DrivAge+VehAge+VehUsage+BonusMalus+VehBody+VehMaxSpeed, offset = ClaimInd, family=poisson(link = "log"), data=freMPL2)
summary(glm4)
predict4 <- predict(glm4, freMPL2, type = 'response')
recap4 <- data.frame(ClaimAmount = freMPL2$ClaimAmount,
                     Predict_ClaimAmount = predict4,
                     difference = abs(freMPL2$ClaimAmount- predict4))
head(recap4,10)
```

### Calcul de la prime pure

Soit X le coût monétaire au risque

Selon le modèle général, X = SOMME de 1 à N des Bk

où N correspond au nombre de sinistres
et Bk correspond au montant de sinistres

Autrement dit, N représente la fréquence (variable discrète) et Bk la sévérité (variable continue positive)

En admettant que la fréquence n'a pas d'influence sur la sévérité et que les montants des sinistres ont le même comportement aléatoire, on a : E(X) = E(N).E(B)   (prime pure). 

Comment calculer E(N)? Comment calculer E(B)?

# Bibliographie

## Internet

- Pour la documantation R : <https://www.rdocumentation.org/>

- Pour l'analyse en composantes prinicipales : <http://www.sthda.com/french/articles/38-methodes-des-composantes-principales-dans-r-guide-pratique/73-acp-analyse-en-composantes-principales-avec-r-l-essentiel/>

- Pour l'analyse factorielle des correspondances : <http://www.sthda.com/french/articles/38-methodes-des-composantes-principales-dans-r-guide-pratique/74-afc-analyse-factorielle-des-correspondances-avec-r-l-essentiel/>
  
## Littérature


# Annexes

## Affichage de l'implementation de la fonction nettoyage_dataframe : 

```
nettoyage_dataframe <- function(dt){
  
  # Suppression des données des individus assurés moins d'un jour (Exposure)
  dt <- subset(dt,dt$Exposure>1/365.25)
  
  # Modification des données des individus ayant un ClaimAmount négatif
  dt <- subset(dt,dt$ClaimAmount>=0)
  
  # Suppression de la colonne associée au sexe de la personne et de ClaimInd
  dt <- dt[,-6]
  dt <- dt[,-21]
  
  # Réduction du nombre de catégories socioprofessionnels
  levels(dt$SocioCateg) <- c(levels(dt$SocioCateg), "CSP4", "CSP6",
                                    "CSP9")
  for (i in 1:dim(dt)[1]){
    if (dt$SocioCateg[i]%in%c("CSP1","CSP16","CSP18","CSP19")){
      dt$SocioCateg[i]<-"CSP1"
      }
    if (dt$SocioCateg[i]%in%c("CSP2", "CSP20", "CSP21", "CSP22", "CSP23",
                                     "CSP25", "CSP26","CSP27", "CSP28")){
      dt$SocioCateg[i]<-"CSP2"
      }
    if (dt$SocioCateg[i]%in%c("CSP3", "CSP30", "CSP31", "CSP32", "CSP33",
                                     "CSP35", "CSP36","CSP37", "CSP38", "CSP39")){
      dt$SocioCateg[i]<-"CSP3"
      }
    if (dt$SocioCateg[i]%in%c("CSP40", "CSP41", "CSP42", "CSP43", "CSP46",
                                     "CSP47", "CSP48","CSP49")){
      dt$SocioCateg[i]<-"CSP4"
      }
    if (dt$SocioCateg[i]%in%c("CSP5", "CSP50", "CSP51", "CSP55", "CSP56", 
                                     "CSP57", "CSP59")){
      dt$SocioCateg[i]<-"CSP5"
      }
    if (dt$SocioCateg[i]%in%c("CSP6", "CSP60", "CSP61", "CSP62", "CSP63",
                                     "CSP65", "CSP66")){
      dt$SocioCateg[i]<-"CSP6"
      }
    if (dt$SocioCateg[i]%in%c("CSP7", "CSP70", "CSP73", "CSP74", "CSP77")){
      dt$SocioCateg[i]<-"CSP7"
      }
    if (dt$SocioCateg[i]%in%c("CSP9", "CSP91")){
      dt$SocioCateg[i]<-"CSP9"
      }
  }
  dt$SocioCateg <- droplevels(dt$SocioCateg)
  
  # Traduction des données (VehBody, MariStat, VehUsage, VehEngine, VehEnergy, Garage)
  for (i in 1:dim(dt)[2]){
    # Type de véhicules
    if (colnames(dt)[i]=="VehBody"){
      levels(dt$VehBody) <- c(levels(dt$VehBody), "autobus", "coupé",
                                     "autre microvan", "berline","SUV", "break",
                                     "camionnette")
      dt$VehBody[dt$VehBody == "bus"]<-"autobus"
      dt$VehBody[dt$VehBody == "coupe"]<-"coupé"
      dt$VehBody[dt$VehBody == "other microvan"]<-"autre microvan"
      dt$VehBody[dt$VehBody == "sedan"]<-"berline"
      dt$VehBody[dt$VehBody == "sport utility vehicle"]<-"SUV"
      dt$VehBody[dt$VehBody == "station wagon"]<-"break"
      dt$VehBody[dt$VehBody == "van"]<-"camionnette"
      dt$VehBody <- droplevels(dt$VehBody)
      }
    # Statut marital
    if (colnames(dt)[i]=="MariStat"){
      levels(dt$MariStat) <- c(levels(dt$MariStat), "célibataire", "autre")
      dt$MariStat[dt$MariStat == "Alone"]<-"célibataire"
      dt$MariStat[dt$MariStat == "Other"]<-"autre"
      dt$MariStat <- droplevels(dt$MariStat)
      }
    # Utilisation du véhicule
    if (colnames(dt)[i]=="VehUsage"){
      levels(dt$VehUsage) <- c(levels(dt$VehUsage), "privée", 
                                      "privée et trajet vers bureau", "professionnel", 
                                      "trajet professionnel" )
      dt$VehUsage[dt$VehUsage == "Private"]<-"privée"
      dt$VehUsage[dt$VehUsage == "Private+trip to office"]<-
      "privée et trajet vers bureau"
      dt$VehUsage[dt$VehUsage == "Professional"]<-"professionnel"
      dt$VehUsage[dt$VehUsage == "Professional run"]<-
      "trajet professionnel"
      dt$VehUsage <- droplevels(dt$VehUsage)
      }
    # Moteur du véhicule
    if (colnames(dt)[i]=="VehEngine"){
      levels(dt$VehEngine) <- c(levels(dt$VehEngine), 
                                       "injection directe surpuissante",
                                       "électrique", "injection surpuissante")
      dt$VehEngine[dt$VehEngine == "direct injection overpowered"]<-
      "injection directe surpuissante"
      dt$VehEngine[dt$VehEngine == "electric"]<-"électrique"
      dt$VehEngine[dt$VehEngine == "injection overpowered"]<-
      "injection surpuissante"
      dt$VehEngine <- droplevels(dt$VehEngine)
      }
    # Energie utilisée par le véhicule
    if (colnames(dt)[i]=="VehEnergy"){
      levels(dt$VehEnergy) <- c(levels(dt$VehEnergy), "électrique", "essence")
      dt$VehEnergy[dt$VehEnergy == "regular"]<-"essence"
      dt$VehEnergy[dt$VehEnergy == "eletric"]<-"électrique"
      dt$VehEnergy <- droplevels(dt$VehEnergy)
      }
    # Garage
    if (colnames(dt)[i]=="Garage"){
      levels(dt$Garage) <- c(levels(dt$Garage), "aucun", "garage indépendant",
                                    "concessionnaire")
      dt$Garage[dt$Garage == "None"]<-"aucun"
      dt$Garage[dt$Garage == "Private garage"]<-"garage indépendant"
      dt$Garage[dt$Garage == "Collective garage"]<-"concessionnaire"
      dt$Garage <- droplevels(dt$Garage)
    }
  }
  return (dt)
}
```
## Affichage d'un exemple d'exécution de la fonction describe du package Hmisc

```{r}
describe_freMPL2
```


## Affichage de l'ensemble des représentations graphiques

|| **freMPL1**  	| **freMPL2** 	|
|:-:|:-:|:-:|
|**`r colnames_freMPL2[1]`**|![](graphique/Exposure1.png){width=40%}|![](graphique/Exposure2.png){width=40%}|
|**`r colnames_freMPL2[2]`**   	|![](graphique/LicAge1.png){width=40%}   	| ![](graphique/LicAge2.png){width=40%}  	|
|  **`r colnames_freMPL2[5]`** 	|![](graphique/VehAge1.png){width=40%}|![](graphique/VehAge2.png){width=40%}|
| **`r colnames_freMPL2[7]`**  	|![](graphique/MariStat1.png){width=40%}|![](graphique/MariStat2.png){width=40%}|
| **`r colnames_freMPL2[8]`**  	|![](graphique/SocioCateg1.png){width=40%}|![](graphique/SocioCateg2.png){width=40%}|
| **`r colnames_freMPL2[9]`**  	| ![](graphique/VehUsage1.png){width=40%}|![](graphique/VehUsage2.png){width=40%}|
| **`r colnames_freMPL2[10]`**  	|![](graphique/DrivAge1.png){width=40%}|![](graphique/DrivAge2.png){width=40%}|
| **`r colnames_freMPL2[11]`**  	|   ![](graphique/HasKmLimit1.png){width=40%}|![](graphique/HasKmLimit2.png){width=40%}|
|**`r colnames_freMPL2[12]`**   	| ![](graphique/BonusMalus1.png){width=40%}|![](graphique/BonusMalus2.png){width=40%}|
|**`r colnames_freMPL2[13]`**   	| ![](graphique/VehBody1.png){width=40%}|![](graphique/VehBody2.png){width=40%}|
|**`r colnames_freMPL2[14]`**   	| ![](graphique/VehPrice1.png){width=40%}|![](graphique/VehPrice2.png){width=40%}|
| **`r colnames_freMPL2[15]`**  	|![](graphique/VehEngine1.png){width=40%}|![](graphique/VehEngine2.png){width=40%}|
| **`r colnames_freMPL2[16]`**  	| ![](graphique/VehEnergy1.png){width=40%}|![](graphique/VehEnergy2.png){width=40%}|
| **`r colnames_freMPL2[17]`**  	| ![](graphique/VehMaxSpeed1.png){width=40%}|![](graphique/VehMaxSpeed2.png){width=40%}|
|   **`r colnames_freMPL2[18]`**	| ![](graphique/VehClass1.png){width=40%}|![](graphique/VehClass2.png){width=40%}|
| **`r colnames_freMPL2[19]`**  	|![](graphique/RiskVar1.png){width=40%}|![](graphique/RiskVar2.png){width=40%}|
| **`r colnames_freMPL2[20]`**  	| ![](graphique/ClaimAmount1.png){width=40%}|![](graphique/ClaimAmount2.png){width=40%}|
| **`r colnames_freMPL2[21]`**  	| ![](graphique/Garage1.png){width=40%}|![](graphique/Garage2.png){width=40%}|
| **`r colnames_freMPL2[22]`**  	| ![](graphique/ClaimInd1.png){width=40%}|![](graphique/ClaimInd2.png){width=40%}|

